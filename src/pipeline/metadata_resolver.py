"""
Metadata Resolver â€” deterministic post-LLM metadata enforcement.

Runs as the final step after all LLM calls, before the clip is written to the
output queue.  Ensures user metadata intent is honoured regardless of what the
LLM returned.

Modes
-----
- ``strict``:  Replace LLM hashtags and description entirely with user-provided
  values.  No exceptions.
- ``append``:  Keep user-provided tags, append up to 5 LLM-generated tags that
  are not duplicates.
- ``ai_only``: Use LLM output only.  User-provided values are ignored (with a
  warning logged).
"""

import logging
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)

VALID_MODES = {"strict", "append", "ai_only"}
MAX_APPENDED_TAGS = 5


def resolve_hashtags(
    mode: str,
    user_tags: List[str],
    llm_tags: List[str],
) -> List[str]:
    """
    Resolve final hashtag list based on *mode*.

    Parameters
    ----------
    mode : str
        One of ``strict``, ``append``, ``ai_only``.
    user_tags : list[str]
        Tags provided by the creator.
    llm_tags : list[str]
        Tags generated by the LLM.

    Returns
    -------
    list[str]
        Final resolved hashtag list.
    """
    if mode not in VALID_MODES:
        logger.warning("Unknown hashtag_mode '%s', falling back to 'append'", mode)
        mode = "append"

    if mode == "strict":
        return list(user_tags)

    if mode == "ai_only":
        if user_tags:
            logger.warning(
                "ai_only mode: user-provided tags %s will be ignored", user_tags
            )
        return list(llm_tags)

    # append mode
    seen = {t.lower() for t in user_tags}
    result = list(user_tags)
    added = 0
    for tag in llm_tags:
        if tag.lower() not in seen and added < MAX_APPENDED_TAGS:
            result.append(tag)
            seen.add(tag.lower())
            added += 1
    return result


def resolve_description(
    mode: str,
    user_description: Optional[str],
    llm_description: Optional[str],
) -> str:
    """
    Resolve final description based on *mode*.

    Parameters
    ----------
    mode : str
        One of ``strict``, ``append``, ``ai_only``.
    user_description : str | None
        Creator-provided description.
    llm_description : str | None
        LLM-generated description.

    Returns
    -------
    str
        Resolved description.
    """
    if mode not in VALID_MODES:
        mode = "append"

    if mode == "strict":
        return (user_description or "").strip()

    if mode == "ai_only":
        return (llm_description or "").strip()

    # append
    parts = []
    if user_description and user_description.strip():
        parts.append(user_description.strip())
    if llm_description and llm_description.strip():
        parts.append(llm_description.strip())
    return " ".join(parts)


def resolve_metadata(
    clip: Dict,
    mode: str,
    user_tags: Optional[List[str]] = None,
    llm_tags: Optional[List[str]] = None,
    user_description: Optional[str] = None,
    llm_description: Optional[str] = None,
) -> Dict:
    """
    Apply metadata resolution to a clip dict.

    This function must be called **after** all LLM calls and **before** the clip
    is written to the output queue.

    Parameters
    ----------
    clip : dict
        The clip record (modified in-place and returned).
    mode : str
        Hashtag/description mode.
    user_tags, llm_tags : list[str] | None
        Creator and LLM tag lists.
    user_description, llm_description : str | None
        Creator and LLM descriptions.

    Returns
    -------
    dict
        The enriched clip dict with resolved ``hashtags`` and ``description``.
    """
    clip["hashtags"] = resolve_hashtags(
        mode,
        user_tags or [],
        llm_tags or [],
    )
    clip["description"] = resolve_description(
        mode,
        user_description,
        llm_description,
    )
    clip["hashtag_mode_used"] = mode

    logger.info(
        "Metadata resolved (mode=%s): %d tags, desc length=%d",
        mode,
        len(clip["hashtags"]),
        len(clip["description"]),
    )

    return clip
